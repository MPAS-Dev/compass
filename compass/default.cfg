# Options related to downloading files
[download]

# the base url for the server from which meshes, initial conditions, and other
# data sets can be downloaded
server_base_url = https://web.lcrc.anl.gov/public/e3sm/mpas_standalonedata

# whether to download files during setup that have not been cached locally
download = True

# whether to check the size of files that have been downloaded to make sure
# they are the right size
check_size = False

# whether to verify SSL certificates for HTTPS requests
verify = True


# The parallel section describes options related to running tests in parallel
[parallel]

# the program to use for graph partitioning
partition_executable = gpmetis


# The io section describes options related to file i/o
[io]

# the NetCDF file format: NETCDF4, NETCDF4_CLASSIC, NETCDF3_64BIT, or
# NETCDF3_CLASSIC
format = NETCDF3_64BIT

# the NetCDF output engine: netcdf4 or scipy
# the netcdf4 engine is not performing well on Chrysalis and Anvil, so we will
# try scipy for now.  If we can switch to NETCDF4 format, netcdf4 will be
# required
engine = scipy


# Config options related to creating a job script
[job]

# the name of the parallel job
job_name = <<<default>>>

# wall-clock time
wall_time = 1:00:00

# The job partition to use, by default, taken from the first partition (if any)
# provided for the machine by mache
partition = <<<default>>>

# The job quality of service (QOS) to use, by default, taken from the first
# qos (if any) provided for the machine by mache
qos = <<<default>>>

# The job constraint to use, by default, taken from the first constraint (if
# any) provided for the  machine by mache
constraint = <<<default>>>
